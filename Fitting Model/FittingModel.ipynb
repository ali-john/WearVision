{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All helper functions for dataloader\n",
    "def load_images(path):\n",
    "    images = []\n",
    "    valid_images = [\".jpeg\", \".jpg\", '.png']\n",
    "    for img in os.listdir(path):\n",
    "        ext = os.path.splitext(img)[1]\n",
    "        if ext.lower() not in valid_images:\n",
    "            continue\n",
    "        else:\n",
    "            images.append(os.path.join(path, img))\n",
    "    return images\n",
    "\n",
    "def denormalize_tensor(normalize_tensor):\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "        std=[1/0.229, 1/0.224, 1/0.255]\n",
    "    )\n",
    "    return inv_normalize(normalize_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataloaderGenerator(object):\n",
    "    def __init__(self, dataset_path, shape=(786,1024)):\n",
    "        super().__init__()\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "        self.cloth_dir_name = 'cloth'\n",
    "        self.cloth_dir_path = os.path.join(self.dataset_path, self.cloth_dir_name)\n",
    "        self.cloth_paths = load_images(self.cloth_dir_path)\n",
    "    \n",
    "\n",
    "        self.cloth_mask_dir_name = 'cloth-mask'\n",
    "        self.cloth_mask_dir_path = os.path.join(self.dataset_path, self.cloth_mask_dir_name)\n",
    "        self.cloth_mask_paths = load_images(self.cloth_mask_dir_path)\n",
    "\n",
    "        self.person_with_cloth_dir_name = 'image'\n",
    "        self.person_with_cloth_dir_path = os.path.join(self.dataset_path,\n",
    "                                                        self.person_with_cloth_dir_name)\n",
    "        self.person_with_cloth_paths = load_images(self.person_with_cloth_dir_path)\n",
    "\n",
    "        self.normalize_img = transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], #mean\n",
    "            [0.229, 0.224, 0.225] #std\n",
    "            )\n",
    "\n",
    "        self.normalize_mask = transforms.Normalize(\n",
    "            [0.5], [0.5]\n",
    "            )\n",
    "\n",
    "        self.transform_img = transforms.Compose([\n",
    "            transforms.Resize(shape),\n",
    "            transforms.CenterCrop(shape),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize_img\n",
    "            ]\n",
    "            \n",
    "            )\n",
    "\n",
    "        self.transform_mask = transforms.Compose([\n",
    "            transforms.Resize(shape),\n",
    "            transforms.CenterCrop(shape),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize_mask\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cloth_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cloth_path = self.cloth_paths[idx]\n",
    "        person_with_cloth_path = self.person_with_cloth_paths[idx]\n",
    "        person_with_cloth_mask_path = self.cloth_mask_paths[idx]\n",
    "\n",
    "        target_cloth_idx = random.randint(0, len(self.cloth_paths)-1)\n",
    "        target_cloth_path = self.cloth_paths[target_cloth_idx]\n",
    "\n",
    "        cloth = Image.open(cloth_path)\n",
    "        person_with_cloth = Image.open(person_with_cloth_path)\n",
    "        person_with_cloth_mask = Image.open(person_with_cloth_mask_path)\n",
    "        target_cloth = Image.open(target_cloth_path)\n",
    "        \n",
    "        cloth = self.transform_img(cloth)\n",
    "        person_with_cloth = self.transform_img(person_with_cloth)\n",
    "        target_cloth = self.transform_img(target_cloth)\n",
    "        person_with_cloth_mask = self.transform_mask(person_with_cloth_mask)\n",
    "\n",
    "        return cloth, person_with_cloth, person_with_cloth_mask, target_cloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataloaderDiscriminator(object):\n",
    "    def __init__(self, dataset_path, shape=(786,1024)):\n",
    "        super().__init__()\n",
    "        self.dataset_path = dataset_path\n",
    "        self.cloth_dir_name = 'cloth'\n",
    "        self.cloth_dir_path = os.path.join(self.dataset_path, self.cloth_dir_name)\n",
    "        self.cloth_paths = load_images(self.cloth_dir_path)\n",
    "    \n",
    "\n",
    "        self.person_with_cloth_dir_name = 'image'\n",
    "        self.person_with_cloth_dir_path = os.path.join(self.dataset_path,\n",
    "                                                        self.person_with_cloth_dir_name)\n",
    "        self.person_with_cloth_paths = load_images(self.person_with_cloth_dir_path)\n",
    "    \n",
    "\n",
    "        self.normalize = transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        self.transform_img = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Resize(shape),\n",
    "            transforms.CenterCrop(shape),\n",
    "            transforms.ToTensor(),\n",
    "            self.normalize])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cloth_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # only return real pair\n",
    "        cloth_path = self.cloth_paths[idx]\n",
    "        person_with_cloth_path = self.person_with_cloth_paths[idx]\n",
    "\n",
    "        cloth = Image.open(cloth_path)\n",
    "        person_with_cloth = Image.open(person_with_cloth_path)\n",
    "    \n",
    "        cloth = self.transform_img(cloth)\n",
    "        person_with_cloth = self.transform_img(person_with_cloth)\n",
    "\n",
    "        return cloth, person_with_cloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_DL_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
